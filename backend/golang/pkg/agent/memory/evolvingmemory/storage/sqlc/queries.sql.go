// Code generated by sqlc. DO NOT EDIT.
// versions:
//   sqlc v1.29.0
// source: queries.sql

package sqlc

import (
	"context"
	"time"

	"github.com/EternisAI/enchanted-twin/pkg/agent/memory/evolvingmemory/storage/types"
	"github.com/jackc/pgx/v5/pgtype"
	pgvector_go "github.com/pgvector/pgvector-go"
)

const createDocumentChunk = `-- name: CreateDocumentChunk :one
INSERT INTO document_chunks (
    id, content, content_vector, chunk_index, original_document_id,
    source, file_path, tags, metadata_json
) VALUES (
    $1, $2, $3, $4, $5, $6, $7, $8, $9
) RETURNING id, content, content_vector, chunk_index, original_document_id, source, file_path, tags, metadata_json, created_at
`

type CreateDocumentChunkParams struct {
	ID                 pgtype.UUID         `json:"id"`
	Content            string              `json:"content"`
	ContentVector      *pgvector_go.Vector `json:"contentVector"`
	ChunkIndex         int32               `json:"chunkIndex"`
	OriginalDocumentID string              `json:"originalDocumentId"`
	Source             string              `json:"source"`
	FilePath           pgtype.Text         `json:"filePath"`
	Tags               []string            `json:"tags"`
	MetadataJson       []byte              `json:"metadataJson"`
}

func (q *Queries) CreateDocumentChunk(ctx context.Context, arg CreateDocumentChunkParams) (DocumentChunk, error) {
	row := q.db.QueryRow(ctx, createDocumentChunk,
		arg.ID,
		arg.Content,
		arg.ContentVector,
		arg.ChunkIndex,
		arg.OriginalDocumentID,
		arg.Source,
		arg.FilePath,
		arg.Tags,
		arg.MetadataJson,
	)
	var i DocumentChunk
	err := row.Scan(
		&i.ID,
		&i.Content,
		&i.ContentVector,
		&i.ChunkIndex,
		&i.OriginalDocumentID,
		&i.Source,
		&i.FilePath,
		&i.Tags,
		&i.MetadataJson,
		&i.CreatedAt,
	)
	return i, err
}

const createMemoryFact = `-- name: CreateMemoryFact :one
INSERT INTO memory_facts (
    id, content, content_vector, timestamp, source, tags, document_references,
    metadata_json, fact_category, fact_subject, fact_attribute, fact_value,
    fact_temporal_context, fact_sensitivity, fact_importance, fact_file_path
) VALUES (
    $1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15, $16
) RETURNING id, content, content_vector, timestamp, source, tags, document_references, metadata_json, fact_category, fact_subject, fact_attribute, fact_value, fact_temporal_context, fact_sensitivity, fact_importance, fact_file_path, created_at
`

type CreateMemoryFactParams struct {
	ID                  pgtype.UUID                   `json:"id"`
	Content             string                        `json:"content"`
	ContentVector       *pgvector_go.Vector           `json:"contentVector"`
	Timestamp           time.Time                     `json:"timestamp"`
	Source              string                        `json:"source"`
	Tags                []string                      `json:"tags"`
	DocumentReferences  []string                      `json:"documentReferences"`
	MetadataJson        []byte                        `json:"metadataJson"`
	FactCategory        pgtype.Text                   `json:"factCategory"`
	FactSubject         types.NullableSanitizedString `json:"factSubject"`
	FactAttribute       pgtype.Text                   `json:"factAttribute"`
	FactValue           pgtype.Text                   `json:"factValue"`
	FactTemporalContext pgtype.Text                   `json:"factTemporalContext"`
	FactSensitivity     pgtype.Text                   `json:"factSensitivity"`
	FactImportance      pgtype.Int4                   `json:"factImportance"`
	FactFilePath        pgtype.Text                   `json:"factFilePath"`
}

func (q *Queries) CreateMemoryFact(ctx context.Context, arg CreateMemoryFactParams) (MemoryFact, error) {
	row := q.db.QueryRow(ctx, createMemoryFact,
		arg.ID,
		arg.Content,
		arg.ContentVector,
		arg.Timestamp,
		arg.Source,
		arg.Tags,
		arg.DocumentReferences,
		arg.MetadataJson,
		arg.FactCategory,
		arg.FactSubject,
		arg.FactAttribute,
		arg.FactValue,
		arg.FactTemporalContext,
		arg.FactSensitivity,
		arg.FactImportance,
		arg.FactFilePath,
	)
	var i MemoryFact
	err := row.Scan(
		&i.ID,
		&i.Content,
		&i.ContentVector,
		&i.Timestamp,
		&i.Source,
		&i.Tags,
		&i.DocumentReferences,
		&i.MetadataJson,
		&i.FactCategory,
		&i.FactSubject,
		&i.FactAttribute,
		&i.FactValue,
		&i.FactTemporalContext,
		&i.FactSensitivity,
		&i.FactImportance,
		&i.FactFilePath,
		&i.CreatedAt,
	)
	return i, err
}

const createSourceDocument = `-- name: CreateSourceDocument :one
INSERT INTO source_documents (
    id, content, content_hash, document_type, original_id, metadata_json
) VALUES (
    $1, $2, $3, $4, $5, $6
) RETURNING id, content, content_hash, document_type, original_id, metadata_json, created_at
`

type CreateSourceDocumentParams struct {
	ID           pgtype.UUID `json:"id"`
	Content      string      `json:"content"`
	ContentHash  string      `json:"contentHash"`
	DocumentType string      `json:"documentType"`
	OriginalID   string      `json:"originalId"`
	MetadataJson []byte      `json:"metadataJson"`
}

func (q *Queries) CreateSourceDocument(ctx context.Context, arg CreateSourceDocumentParams) (SourceDocument, error) {
	row := q.db.QueryRow(ctx, createSourceDocument,
		arg.ID,
		arg.Content,
		arg.ContentHash,
		arg.DocumentType,
		arg.OriginalID,
		arg.MetadataJson,
	)
	var i SourceDocument
	err := row.Scan(
		&i.ID,
		&i.Content,
		&i.ContentHash,
		&i.DocumentType,
		&i.OriginalID,
		&i.MetadataJson,
		&i.CreatedAt,
	)
	return i, err
}

const deleteMemoryFact = `-- name: DeleteMemoryFact :exec
DELETE FROM memory_facts WHERE id = $1
`

func (q *Queries) DeleteMemoryFact(ctx context.Context, id pgtype.UUID) error {
	_, err := q.db.Exec(ctx, deleteMemoryFact, id)
	return err
}

const getDocumentChunk = `-- name: GetDocumentChunk :one

SELECT id, content, content_vector, chunk_index, original_document_id, source, file_path, tags, metadata_json, created_at FROM document_chunks
WHERE id = $1
`

// Document Chunks Queries
func (q *Queries) GetDocumentChunk(ctx context.Context, id pgtype.UUID) (DocumentChunk, error) {
	row := q.db.QueryRow(ctx, getDocumentChunk, id)
	var i DocumentChunk
	err := row.Scan(
		&i.ID,
		&i.Content,
		&i.ContentVector,
		&i.ChunkIndex,
		&i.OriginalDocumentID,
		&i.Source,
		&i.FilePath,
		&i.Tags,
		&i.MetadataJson,
		&i.CreatedAt,
	)
	return i, err
}

const getDocumentChunksByOriginalDocument = `-- name: GetDocumentChunksByOriginalDocument :many
SELECT id, content, content_vector, chunk_index, original_document_id, source, file_path, tags, metadata_json, created_at FROM document_chunks
WHERE original_document_id = $1
ORDER BY chunk_index
`

func (q *Queries) GetDocumentChunksByOriginalDocument(ctx context.Context, originalDocumentID string) ([]DocumentChunk, error) {
	rows, err := q.db.Query(ctx, getDocumentChunksByOriginalDocument, originalDocumentID)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	items := []DocumentChunk{}
	for rows.Next() {
		var i DocumentChunk
		if err := rows.Scan(
			&i.ID,
			&i.Content,
			&i.ContentVector,
			&i.ChunkIndex,
			&i.OriginalDocumentID,
			&i.Source,
			&i.FilePath,
			&i.Tags,
			&i.MetadataJson,
			&i.CreatedAt,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getMemoryFact = `-- name: GetMemoryFact :one

SELECT id, content, content_vector, timestamp, source, tags, document_references, metadata_json, fact_category, fact_subject, fact_attribute, fact_value, fact_temporal_context, fact_sensitivity, fact_importance, fact_file_path, created_at FROM memory_facts
WHERE id = $1
`

// Memory Facts Queries
func (q *Queries) GetMemoryFact(ctx context.Context, id pgtype.UUID) (MemoryFact, error) {
	row := q.db.QueryRow(ctx, getMemoryFact, id)
	var i MemoryFact
	err := row.Scan(
		&i.ID,
		&i.Content,
		&i.ContentVector,
		&i.Timestamp,
		&i.Source,
		&i.Tags,
		&i.DocumentReferences,
		&i.MetadataJson,
		&i.FactCategory,
		&i.FactSubject,
		&i.FactAttribute,
		&i.FactValue,
		&i.FactTemporalContext,
		&i.FactSensitivity,
		&i.FactImportance,
		&i.FactFilePath,
		&i.CreatedAt,
	)
	return i, err
}

const getMemoryFactsByIDs = `-- name: GetMemoryFactsByIDs :many
SELECT id, content, content_vector, timestamp, source, tags, document_references, metadata_json, fact_category, fact_subject, fact_attribute, fact_value, fact_temporal_context, fact_sensitivity, fact_importance, fact_file_path, created_at FROM memory_facts
WHERE id = ANY($1::uuid[])
LIMIT 1000
`

func (q *Queries) GetMemoryFactsByIDs(ctx context.Context, dollar_1 []pgtype.UUID) ([]MemoryFact, error) {
	rows, err := q.db.Query(ctx, getMemoryFactsByIDs, dollar_1)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	items := []MemoryFact{}
	for rows.Next() {
		var i MemoryFact
		if err := rows.Scan(
			&i.ID,
			&i.Content,
			&i.ContentVector,
			&i.Timestamp,
			&i.Source,
			&i.Tags,
			&i.DocumentReferences,
			&i.MetadataJson,
			&i.FactCategory,
			&i.FactSubject,
			&i.FactAttribute,
			&i.FactValue,
			&i.FactTemporalContext,
			&i.FactSensitivity,
			&i.FactImportance,
			&i.FactFilePath,
			&i.CreatedAt,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getSourceDocument = `-- name: GetSourceDocument :one

SELECT id, content, content_hash, document_type, original_id, metadata_json, created_at FROM source_documents
WHERE id = $1
`

// Source Documents Queries
func (q *Queries) GetSourceDocument(ctx context.Context, id pgtype.UUID) (SourceDocument, error) {
	row := q.db.QueryRow(ctx, getSourceDocument, id)
	var i SourceDocument
	err := row.Scan(
		&i.ID,
		&i.Content,
		&i.ContentHash,
		&i.DocumentType,
		&i.OriginalID,
		&i.MetadataJson,
		&i.CreatedAt,
	)
	return i, err
}

const getSourceDocumentByHash = `-- name: GetSourceDocumentByHash :one
SELECT id, content, content_hash, document_type, original_id, metadata_json, created_at FROM source_documents
WHERE content_hash = $1
`

func (q *Queries) GetSourceDocumentByHash(ctx context.Context, contentHash string) (SourceDocument, error) {
	row := q.db.QueryRow(ctx, getSourceDocumentByHash, contentHash)
	var i SourceDocument
	err := row.Scan(
		&i.ID,
		&i.Content,
		&i.ContentHash,
		&i.DocumentType,
		&i.OriginalID,
		&i.MetadataJson,
		&i.CreatedAt,
	)
	return i, err
}

const getSourceDocumentsBatch = `-- name: GetSourceDocumentsBatch :many
SELECT id, content, content_hash, document_type, original_id, metadata_json, created_at FROM source_documents
WHERE id = ANY($1::uuid[])
LIMIT 1000
`

func (q *Queries) GetSourceDocumentsBatch(ctx context.Context, dollar_1 []pgtype.UUID) ([]SourceDocument, error) {
	rows, err := q.db.Query(ctx, getSourceDocumentsBatch, dollar_1)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	items := []SourceDocument{}
	for rows.Next() {
		var i SourceDocument
		if err := rows.Scan(
			&i.ID,
			&i.Content,
			&i.ContentHash,
			&i.DocumentType,
			&i.OriginalID,
			&i.MetadataJson,
			&i.CreatedAt,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const queryDocumentChunksByVector = `-- name: QueryDocumentChunksByVector :many
SELECT id, content, content_vector, chunk_index, original_document_id, source, file_path, tags, metadata_json, created_at, content_vector <=> $1 AS distance
FROM document_chunks
WHERE ($2::text IS NULL OR source = $2)
  AND ($3::text IS NULL OR file_path = $3)
  AND ($4::text[] IS NULL OR tags && $4)
  AND ($6::float = 0 OR content_vector <=> $1 <= $6)
ORDER BY content_vector <=> $1
LIMIT $5
`

type QueryDocumentChunksByVectorParams struct {
	ContentVector *pgvector_go.Vector `json:"contentVector"`
	Column2       string              `json:"column2"`
	Column3       string              `json:"column3"`
	Column4       []string            `json:"column4"`
	Limit         int32               `json:"limit"`
	Column6       float64             `json:"column6"`
}

type QueryDocumentChunksByVectorRow struct {
	ID                 pgtype.UUID         `json:"id"`
	Content            string              `json:"content"`
	ContentVector      *pgvector_go.Vector `json:"contentVector"`
	ChunkIndex         int32               `json:"chunkIndex"`
	OriginalDocumentID string              `json:"originalDocumentId"`
	Source             string              `json:"source"`
	FilePath           pgtype.Text         `json:"filePath"`
	Tags               []string            `json:"tags"`
	MetadataJson       []byte              `json:"metadataJson"`
	CreatedAt          time.Time           `json:"createdAt"`
	Distance           interface{}         `json:"distance"`
}

func (q *Queries) QueryDocumentChunksByVector(ctx context.Context, arg QueryDocumentChunksByVectorParams) ([]QueryDocumentChunksByVectorRow, error) {
	rows, err := q.db.Query(ctx, queryDocumentChunksByVector,
		arg.ContentVector,
		arg.Column2,
		arg.Column3,
		arg.Column4,
		arg.Limit,
		arg.Column6,
	)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	items := []QueryDocumentChunksByVectorRow{}
	for rows.Next() {
		var i QueryDocumentChunksByVectorRow
		if err := rows.Scan(
			&i.ID,
			&i.Content,
			&i.ContentVector,
			&i.ChunkIndex,
			&i.OriginalDocumentID,
			&i.Source,
			&i.FilePath,
			&i.Tags,
			&i.MetadataJson,
			&i.CreatedAt,
			&i.Distance,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const queryMemoryFactsByVector = `-- name: QueryMemoryFactsByVector :many
SELECT id, content, content_vector, timestamp, source, tags, document_references, metadata_json, fact_category, fact_subject, fact_attribute, fact_value, fact_temporal_context, fact_sensitivity, fact_importance, fact_file_path, created_at, content_vector <=> $1 AS distance
FROM memory_facts
WHERE ($2::text = '' OR source = $2)
  AND ($3::text = '' OR fact_category = $3)
  AND ($4::text = '' OR fact_subject ILIKE '%' || $4 || '%')
  AND ($5::int = 0 OR fact_importance = $5)
  AND ($6::int = 0 OR fact_importance >= $6)
  AND ($7::int = 0 OR fact_importance <= $7)
  AND ($8::timestamptz IS NULL OR timestamp >= $8)
  AND ($9::timestamptz IS NULL OR timestamp <= $9)
  AND ($10::text = '' OR fact_file_path = $10)
  AND ($11::text[] IS NULL OR tags && $11)
  AND ($12::text[] IS NULL OR document_references && $12)
  AND ($14::float = 0 OR content_vector <=> $1 <= $14)
ORDER BY content_vector <=> $1
LIMIT $13
`

type QueryMemoryFactsByVectorParams struct {
	ContentVector *pgvector_go.Vector `json:"contentVector"`
	Column2       string              `json:"column2"`
	Column3       string              `json:"column3"`
	Column4       string              `json:"column4"`
	Column5       int32               `json:"column5"`
	Column6       int32               `json:"column6"`
	Column7       int32               `json:"column7"`
	Column8       pgtype.Timestamptz  `json:"column8"`
	Column9       pgtype.Timestamptz  `json:"column9"`
	Column10      string              `json:"column10"`
	Column11      []string            `json:"column11"`
	Column12      []string            `json:"column12"`
	Limit         int32               `json:"limit"`
	Column14      float64             `json:"column14"`
}

type QueryMemoryFactsByVectorRow struct {
	ID                  pgtype.UUID                   `json:"id"`
	Content             string                        `json:"content"`
	ContentVector       *pgvector_go.Vector           `json:"contentVector"`
	Timestamp           time.Time                     `json:"timestamp"`
	Source              string                        `json:"source"`
	Tags                []string                      `json:"tags"`
	DocumentReferences  []string                      `json:"documentReferences"`
	MetadataJson        []byte                        `json:"metadataJson"`
	FactCategory        pgtype.Text                   `json:"factCategory"`
	FactSubject         types.NullableSanitizedString `json:"factSubject"`
	FactAttribute       pgtype.Text                   `json:"factAttribute"`
	FactValue           pgtype.Text                   `json:"factValue"`
	FactTemporalContext pgtype.Text                   `json:"factTemporalContext"`
	FactSensitivity     pgtype.Text                   `json:"factSensitivity"`
	FactImportance      pgtype.Int4                   `json:"factImportance"`
	FactFilePath        pgtype.Text                   `json:"factFilePath"`
	CreatedAt           time.Time                     `json:"createdAt"`
	Distance            interface{}                   `json:"distance"`
}

func (q *Queries) QueryMemoryFactsByVector(ctx context.Context, arg QueryMemoryFactsByVectorParams) ([]QueryMemoryFactsByVectorRow, error) {
	rows, err := q.db.Query(ctx, queryMemoryFactsByVector,
		arg.ContentVector,
		arg.Column2,
		arg.Column3,
		arg.Column4,
		arg.Column5,
		arg.Column6,
		arg.Column7,
		arg.Column8,
		arg.Column9,
		arg.Column10,
		arg.Column11,
		arg.Column12,
		arg.Limit,
		arg.Column14,
	)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	items := []QueryMemoryFactsByVectorRow{}
	for rows.Next() {
		var i QueryMemoryFactsByVectorRow
		if err := rows.Scan(
			&i.ID,
			&i.Content,
			&i.ContentVector,
			&i.Timestamp,
			&i.Source,
			&i.Tags,
			&i.DocumentReferences,
			&i.MetadataJson,
			&i.FactCategory,
			&i.FactSubject,
			&i.FactAttribute,
			&i.FactValue,
			&i.FactTemporalContext,
			&i.FactSensitivity,
			&i.FactImportance,
			&i.FactFilePath,
			&i.CreatedAt,
			&i.Distance,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const queryMemoryFactsFilterOnly = `-- name: QueryMemoryFactsFilterOnly :many
SELECT id, content, content_vector, timestamp, source, tags, document_references, metadata_json, fact_category, fact_subject, fact_attribute, fact_value, fact_temporal_context, fact_sensitivity, fact_importance, fact_file_path, created_at
FROM memory_facts
WHERE ($1::text IS NULL OR source = $1)
  AND ($2::text IS NULL OR fact_category = $2)
  AND ($3::text IS NULL OR fact_subject ILIKE '%' || $3 || '%')
  AND ($4::int IS NULL OR fact_importance = $4)
  AND ($5::int IS NULL OR fact_importance >= $5)
  AND ($6::int IS NULL OR fact_importance <= $6)
  AND ($7::timestamptz IS NULL OR timestamp >= $7)
  AND ($8::timestamptz IS NULL OR timestamp <= $8)
  AND ($9::text IS NULL OR fact_file_path = $9)
  AND ($10::text[] IS NULL OR tags && $10)
  AND ($11::text[] IS NULL OR document_references && $11)
ORDER BY created_at DESC
LIMIT $12
`

type QueryMemoryFactsFilterOnlyParams struct {
	Column1  string             `json:"column1"`
	Column2  string             `json:"column2"`
	Column3  string             `json:"column3"`
	Column4  int32              `json:"column4"`
	Column5  int32              `json:"column5"`
	Column6  int32              `json:"column6"`
	Column7  pgtype.Timestamptz `json:"column7"`
	Column8  pgtype.Timestamptz `json:"column8"`
	Column9  string             `json:"column9"`
	Column10 []string           `json:"column10"`
	Column11 []string           `json:"column11"`
	Limit    int32              `json:"limit"`
}

func (q *Queries) QueryMemoryFactsFilterOnly(ctx context.Context, arg QueryMemoryFactsFilterOnlyParams) ([]MemoryFact, error) {
	rows, err := q.db.Query(ctx, queryMemoryFactsFilterOnly,
		arg.Column1,
		arg.Column2,
		arg.Column3,
		arg.Column4,
		arg.Column5,
		arg.Column6,
		arg.Column7,
		arg.Column8,
		arg.Column9,
		arg.Column10,
		arg.Column11,
		arg.Limit,
	)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	items := []MemoryFact{}
	for rows.Next() {
		var i MemoryFact
		if err := rows.Scan(
			&i.ID,
			&i.Content,
			&i.ContentVector,
			&i.Timestamp,
			&i.Source,
			&i.Tags,
			&i.DocumentReferences,
			&i.MetadataJson,
			&i.FactCategory,
			&i.FactSubject,
			&i.FactAttribute,
			&i.FactValue,
			&i.FactTemporalContext,
			&i.FactSensitivity,
			&i.FactImportance,
			&i.FactFilePath,
			&i.CreatedAt,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const updateMemoryFact = `-- name: UpdateMemoryFact :one
UPDATE memory_facts SET
    content = $2,
    content_vector = $3,
    timestamp = $4,
    source = $5,
    tags = $6,
    document_references = $7,
    metadata_json = $8,
    fact_category = $9,
    fact_subject = $10,
    fact_attribute = $11,
    fact_value = $12,
    fact_temporal_context = $13,
    fact_sensitivity = $14,
    fact_importance = $15,
    fact_file_path = $16
WHERE id = $1
RETURNING id, content, content_vector, timestamp, source, tags, document_references, metadata_json, fact_category, fact_subject, fact_attribute, fact_value, fact_temporal_context, fact_sensitivity, fact_importance, fact_file_path, created_at
`

type UpdateMemoryFactParams struct {
	ID                  pgtype.UUID                   `json:"id"`
	Content             string                        `json:"content"`
	ContentVector       *pgvector_go.Vector           `json:"contentVector"`
	Timestamp           time.Time                     `json:"timestamp"`
	Source              string                        `json:"source"`
	Tags                []string                      `json:"tags"`
	DocumentReferences  []string                      `json:"documentReferences"`
	MetadataJson        []byte                        `json:"metadataJson"`
	FactCategory        pgtype.Text                   `json:"factCategory"`
	FactSubject         types.NullableSanitizedString `json:"factSubject"`
	FactAttribute       pgtype.Text                   `json:"factAttribute"`
	FactValue           pgtype.Text                   `json:"factValue"`
	FactTemporalContext pgtype.Text                   `json:"factTemporalContext"`
	FactSensitivity     pgtype.Text                   `json:"factSensitivity"`
	FactImportance      pgtype.Int4                   `json:"factImportance"`
	FactFilePath        pgtype.Text                   `json:"factFilePath"`
}

func (q *Queries) UpdateMemoryFact(ctx context.Context, arg UpdateMemoryFactParams) (MemoryFact, error) {
	row := q.db.QueryRow(ctx, updateMemoryFact,
		arg.ID,
		arg.Content,
		arg.ContentVector,
		arg.Timestamp,
		arg.Source,
		arg.Tags,
		arg.DocumentReferences,
		arg.MetadataJson,
		arg.FactCategory,
		arg.FactSubject,
		arg.FactAttribute,
		arg.FactValue,
		arg.FactTemporalContext,
		arg.FactSensitivity,
		arg.FactImportance,
		arg.FactFilePath,
	)
	var i MemoryFact
	err := row.Scan(
		&i.ID,
		&i.Content,
		&i.ContentVector,
		&i.Timestamp,
		&i.Source,
		&i.Tags,
		&i.DocumentReferences,
		&i.MetadataJson,
		&i.FactCategory,
		&i.FactSubject,
		&i.FactAttribute,
		&i.FactValue,
		&i.FactTemporalContext,
		&i.FactSensitivity,
		&i.FactImportance,
		&i.FactFilePath,
		&i.CreatedAt,
	)
	return i, err
}
